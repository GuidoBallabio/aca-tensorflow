{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Cifar-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we are used:\n",
    "* Python 3.6\n",
    "* Tensorflow 1.8.0\n",
    "* *GPUs parallel calculation manager* nVidia CUDA 9.0\n",
    "* *GPU-accelerated library* nVidia cuDNN 7.1\n",
    "* or CPU optimized tensorflow for intel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first notebook we are going to explain how we have set up our work.  \n",
    "Essentially the process is divided into several parts:\n",
    "* Set up environment with the Cifar-10 Dataset\n",
    "* Define a convolutional neural network\n",
    "* Define a quantization method\n",
    "* Train the convolutional neural network\n",
    "* Provide information about CNN's performance and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daibak/.virtualenvs/aca/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cifar-10 Dataset is taken from the official website www.cs.toronto.edu.\n",
    "\n",
    "Dataset is stored in the data directory: cnn/data. From Cifar-10 dataset we are going to take x_train, t_train, x_test and t_test.\n",
    "The training dataset set is used for training the CNN, the testing dataset is used for evaluate the performance and the accuracy of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.dense import dataset_preprocessing_by_keras\n",
    "from cnn.utils.dataset import load_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, t_train, x_test, t_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 10), (10000, 32, 32, 3), (10000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, t_train.shape, x_test.shape, t_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.68747891, -0.65572952, -0.63985482, ..., -0.95734874,\n",
       "        -1.00497283, -0.92559935],\n",
       "       [-0.65572952, -0.63985482, -0.59223073, ..., -0.92559935,\n",
       "        -1.02084753, -0.86210057],\n",
       "       [-0.7192283 , -0.63985482, -0.65572952, ..., -0.68747891,\n",
       "        -0.735103  , -0.70335361],\n",
       "       ...,\n",
       "       [-0.36998499, -0.7509777 , -1.00497283, ..., -0.25886212,\n",
       "        -0.24298742, -0.14773924],\n",
       "       [-0.25886212, -0.65572952, -1.19546919, ...,  0.31262694,\n",
       "        -0.00486698, -0.49698256],\n",
       "       [-0.27473681, -0.35411029, -1.11609571, ...,  0.75711843,\n",
       "         0.64599556,  0.28087755]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = dataset_preprocessing_by_keras(x_train)\n",
    "x_train[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a custom made wrapper for tensorfllow NN training and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.model_class import TfClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CNN is called *dense_cnn*. Here we will explain how it is composed.\n",
    "\n",
    "The CNN is composed by several layers. In the first part there are 2 **convolutional** layers and 2 **pooling** layers (they are alternated), then there are a *flatten* layer followed by a **relu** layer, a *dropout* layer and finally a **softmax** layer.\n",
    "\n",
    "The network uses a stochastic gradient descent optimizer and a categorical crossentropy loss.  \n",
    "To judge the performance of our model we are used a MSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.dense import NET_NAME, eval_fn, forward_pass, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfClassifier(NET_NAME, forward_pass, loss_fn, eval_fn,\n",
    "                     tf.train.AdamOptimizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is trained for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training: tensorboard --logdir=/tmp/log-tb/dense_cnn/training\n",
      "For validation: tensorboard --logdir=/tmp/log-tb/dense_cnn/validation\n",
      "{'logits': (array([[-1.6053854 , -4.246429  ,  5.0941772 , ..., -0.6970232 ,\n",
      "        -5.673515  , -4.8350163 ],\n",
      "       [ 1.761953  ,  5.598804  , -2.5832732 , ..., -3.3057792 ,\n",
      "         1.4104544 ,  2.1913252 ],\n",
      "       [-0.88071483, -4.566551  ,  2.7711875 , ...,  0.2918641 ,\n",
      "        -2.5259957 , -3.6575155 ],\n",
      "       ...,\n",
      "       [-1.5393044 , -1.3804327 ,  0.9303486 , ...,  1.4802741 ,\n",
      "        -1.8955607 , -0.6082491 ],\n",
      "       [ 1.4340172 , -1.4717604 ,  0.06926289, ...,  1.8782444 ,\n",
      "        -1.6575274 , -1.7713311 ],\n",
      "       [ 1.1731653 , -1.32896   ,  0.2755871 , ..., -2.0149953 ,\n",
      "         5.3643284 , -1.479304  ]], dtype=float32),), 'classes': (array([2, 1, 4, ..., 3, 4, 8]),), 'probabilities': (array([[7.70589220e-04, 5.49328397e-05, 6.25757396e-01, ...,\n",
      "        1.91125891e-03, 1.31842835e-05, 3.04938349e-05],\n",
      "       [2.01109033e-02, 9.32727695e-01, 2.60809757e-04, ...,\n",
      "        1.26632047e-04, 1.41506931e-02, 3.08962427e-02],\n",
      "       [6.30221935e-03, 1.58035691e-04, 2.42937535e-01, ...,\n",
      "        2.03581434e-02, 1.21606595e-03, 3.92233196e-04],\n",
      "       ...,\n",
      "       [9.52324457e-03, 1.11630280e-02, 1.12548977e-01, ...,\n",
      "        1.95061326e-01, 6.66906126e-03, 2.41622310e-02],\n",
      "       [1.56980678e-01, 8.58782325e-03, 4.00996841e-02, ...,\n",
      "        2.44777560e-01, 7.13190297e-03, 6.36474835e-03],\n",
      "       [1.46757485e-02, 1.20210124e-03, 5.98118128e-03, ...,\n",
      "        6.05340290e-04, 9.70061421e-01, 1.03430240e-03]], dtype=float32),), 'accuracy': ((0.5852, 0.5916),), 'mse': ((5.6537056, 5.810301),), 'loss': (1.1363097,), 'summaries': (b'\\n\\x0b\\n\\x04loss\\x15\\x99r\\x91?\\n\\x11\\n\\naccuracy_1\\x15\\xab\\xcf\\x15?\\n\\n\\n\\x03mse\\x15(\\xeb\\xb4@',)}\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "   [x_train, t_train],\n",
    "   batch_size=64,\n",
    "   validation_split=0.1,\n",
    "   epochs=1,\n",
    "   verbosity=1)\n",
    "\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it's evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/daibak/Documents/Code/Python/aca-tensorflow/cnn/models/dense_cnn/model.ckpt\n",
      "[{'logits': array([[ 143.62994  , -162.08067  ,   42.191814 , ...,  -15.134544 ,\n",
      "         -94.737434 , -133.87408  ],\n",
      "       [  -8.582195 , -143.44426  ,  -39.467503 , ...,  117.37074  ,\n",
      "        -114.246216 , -128.47139  ],\n",
      "       [ 105.81731  ,  -58.2278   ,  -25.783539 , ...,    2.7358868,\n",
      "          62.31189  ,  -11.515966 ],\n",
      "       ...,\n",
      "       [  -8.515465 ,  -33.20478  ,  -32.623478 , ...,  170.77232  ,\n",
      "         -94.286194 ,  -71.96053  ],\n",
      "       [  21.121075 ,   99.4205   , -147.48598  , ...,   96.332954 ,\n",
      "           8.045321 ,  158.54713  ],\n",
      "       [  32.10434  ,  -58.17401  ,   -6.9632416, ...,    2.567219 ,\n",
      "         -10.743353 ,   28.20866  ]], dtype=float32), 'classes': array([0, 7, 0, ..., 7, 9, 0]), 'probabilities': array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 9.9998796e-01,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.2759615e-19, 0.0000000e+00],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 2.0971513e-26, 0.0000000e+00, ..., 9.5658822e-28,\n",
      "        0.0000000e+00, 1.0000000e+00],\n",
      "       [9.7327596e-01, 0.0000000e+00, 1.0505123e-17, ..., 1.4468631e-13,\n",
      "        2.3972803e-19, 1.9786270e-02]], dtype=float32), 'accuracy': (0.0, 0.4375), 'mse': (0.0, 11694.488), 'loss': 42.300095, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15L3)B\\n\\x11\\n\\naccuracy_1\\x15\\x00\\x00\\x00\\x00\\n\\n\\n\\x03mse\\x15\\x00\\x00\\x00\\x00'}, {'logits': array([[ -61.787624 ,   -9.250367 ,  -33.297916 , ...,  -32.483902 ,\n",
      "         -52.591805 ,   51.943657 ],\n",
      "       [  81.41416  ,   81.19236  ,  -84.498825 , ...,   -5.8127575,\n",
      "          47.81952  ,  108.42777  ],\n",
      "       [   9.79711  ,  -58.044792 ,    3.1153553, ...,   62.31427  ,\n",
      "          24.998789 ,   -8.157935 ],\n",
      "       ...,\n",
      "       [ -14.766134 ,   -9.804883 , -109.551926 , ...,   78.84473  ,\n",
      "         -48.925945 ,  172.38928  ],\n",
      "       [  79.11843  ,    9.410012 ,  -30.236864 , ...,  -11.096004 ,\n",
      "          40.574177 ,  -47.901024 ],\n",
      "       [ 160.51047  ,  -60.275814 ,    8.110137 , ...,  -36.54045  ,\n",
      "        -100.00097  ,  -82.0828   ]], dtype=float32), 'classes': array([9, 9, 7, ..., 9, 0, 0]), 'probabilities': array([[0.0000000e+00, 2.6527343e-27, 9.5493479e-38, ..., 2.1552486e-37,\n",
      "        0.0000000e+00, 9.9981636e-01],\n",
      "       [1.8541204e-12, 1.4852878e-12, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        4.7661755e-27, 1.0000000e+00],\n",
      "       [1.5562806e-23, 0.0000000e+00, 1.9509160e-26, ..., 1.0000000e+00,\n",
      "        6.2243164e-17, 2.4791902e-31],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 5.3213035e-31, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.8215584e-17, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), 'accuracy': (0.4375, 0.43575), 'mse': (11694.488, 11930.995), 'loss': 43.55775, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15#;.B\\n\\x11\\n\\naccuracy_1\\x15\\x00\\x00\\xe0>\\n\\n\\n\\x03mse\\x15\\xf4\\xb96F'}, {'logits': array([[ 195.7049   ,   52.02106  ,  -24.45002  , ...,   22.01098  ,\n",
      "          58.598415 ,   39.211685 ],\n",
      "       [ 306.23755  ,  167.29175  ,  -55.85832  , ...,   12.231704 ,\n",
      "          19.323076 ,   75.15361  ],\n",
      "       [ 223.73474  ,   96.2243   ,  -31.140245 , ...,   51.24883  ,\n",
      "         109.497925 ,   60.025116 ],\n",
      "       ...,\n",
      "       [  23.918715 ,   34.605206 ,    4.821559 , ...,   66.01168  ,\n",
      "         -46.12655  ,    3.209531 ],\n",
      "       [  29.18023  ,  -86.98379  ,  -10.863628 , ...,  -28.411032 ,\n",
      "        -135.91089  ,  -56.414158 ],\n",
      "       [  99.661    ,   43.56739  ,   -5.9708395, ...,  -17.913698 ,\n",
      "          41.35458  ,  -44.5772   ]], dtype=float32), 'classes': array([0, 0, 0, ..., 4, 6, 0]), 'probabilities': array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.7330993e-22, 1.6336266e-17, 1.8979212e-30, ..., 7.1254378e-04,\n",
      "        0.0000000e+00, 3.7860449e-31],\n",
      "       [3.7262346e-21, 0.0000000e+00, 1.5151031e-38, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 4.3536509e-25, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        4.7625795e-26, 0.0000000e+00]], dtype=float32), 'accuracy': (0.43575, 0.43816668), 'mse': (11930.995, 11868.18), 'loss': 42.75307, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15%\\x03+B\\n\\x11\\n\\naccuracy_1\\x15\\xa0\\x1a\\xdf>\\n\\n\\n\\x03mse\\x15\\xfbk:F'}, {'logits': array([[ 120.930534 , -105.319786 ,  -16.409231 , ...,   55.976234 ,\n",
      "        -188.95111  ,  -77.47716  ],\n",
      "       [ -88.854294 , -153.65546  ,  -97.117355 , ...,  225.42523  ,\n",
      "        -122.90507  ,   16.840252 ],\n",
      "       [ -21.664137 ,  -31.661991 ,   -7.2789583, ...,   66.110886 ,\n",
      "         -70.90041  ,  -26.614576 ],\n",
      "       ...,\n",
      "       [   1.9695458, -263.98825  ,   24.266958 , ...,  179.14665  ,\n",
      "        -139.48419  , -153.051    ],\n",
      "       [ -16.232143 ,   82.91222  ,  -32.260326 , ...,  -69.134415 ,\n",
      "         -39.308674 ,   84.13553  ],\n",
      "       [-122.04166  ,    6.6214027,  -17.813147 , ...,  -61.851425 ,\n",
      "         -41.38885  ,   27.765316 ]], dtype=float32), 'classes': array([0, 7, 7, ..., 5, 9, 6]), 'probabilities': array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 6.1759825e-29,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 1.3402769e-32, ..., 9.9999988e-01,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 3.3613029e-10,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 2.2735408e-01, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 7.7264595e-01],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 1.5189747e-34]], dtype=float32), 'accuracy': (0.43816668, 0.434625), 'mse': (11868.18, 11932.88), 'loss': 42.058334, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\xbc;(B\\n\\x11\\n\\naccuracy_1\\x15bW\\xe0>\\n\\n\\n\\x03mse\\x15\\xb8p9F'}, {'logits': array([[ -49.94972  ,    2.8032298,  -53.651688 , ...,  -24.646564 ,\n",
      "         -62.43273  ,   28.29241  ],\n",
      "       [  69.62754  , -141.9486   ,  -23.695553 , ...,   98.04856  ,\n",
      "          -6.911466 ,    7.901415 ],\n",
      "       [  -9.504295 ,   -5.8507957,   -4.115102 , ...,  -34.27045  ,\n",
      "          19.166285 ,  -15.12906  ],\n",
      "       ...,\n",
      "       [  37.49826  ,  -13.141034 ,  -84.11209  , ...,   61.771294 ,\n",
      "          67.72337  ,   62.332214 ],\n",
      "       [   7.846171 ,  -99.85854  ,  -60.47294  , ...,   71.424225 ,\n",
      "          25.868296 ,   41.340252 ],\n",
      "       [ 123.28879  ,  -14.749175 ,    4.007987 , ...,  307.61096  ,\n",
      "        -140.93103  ,  -15.697372 ]], dtype=float32), 'classes': array([3, 7, 8, ..., 8, 7, 7]), 'probabilities': array([[0.00000000e+00, 8.65223838e-19, 0.00000000e+00, ...,\n",
      "        1.03713218e-30, 0.00000000e+00, 1.01610475e-07],\n",
      "       [4.53845105e-13, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [3.48766616e-13, 1.34657207e-11, 7.63891173e-11, ...,\n",
      "        6.11969142e-24, 9.86301064e-01, 1.25814388e-15],\n",
      "       ...,\n",
      "       [7.41827728e-14, 7.54980403e-36, 0.00000000e+00, ...,\n",
      "        2.58194725e-03, 9.92893755e-01, 4.52430779e-03],\n",
      "       [2.44569727e-28, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.00000000e+00, 1.64176336e-20, 8.60392486e-14],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), 'accuracy': (0.434625, 0.4345), 'mse': (11932.88, 12107.361), 'loss': 43.01454, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\xe4\\x0e,B\\n\\x11\\n\\naccuracy_1\\x15+\\x87\\xde>\\n\\n\\n\\x03mse\\x15\\x85s:F'}]\n"
     ]
    }
   ],
   "source": [
    "evals = model.evaluate([x_test, t_test])\n",
    "\n",
    "print(evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [x_train, t_train]\n",
    "input_names = [\"features\", \"labels\"]\n",
    "batch_size = 64\n",
    "validation_split = 0.2\n",
    "MAX_BATCH_SIZE = 2000\n",
    "\n",
    "n_samples = inputs[0].shape[0]\n",
    "\n",
    "input_tensors = input_names\n",
    "input_DL = dict(zip(input_tensors, inputs))\n",
    "\n",
    "input_LD = _split_data_dict_in_perc(input_DL, n_samples,\n",
    "                                    np.array([1 - validation_split]))\n",
    "\n",
    "train_dict = input_LD[0]\n",
    "val_dict = input_LD[1]\n",
    "\n",
    "n_train_samples = train_dict[input_tensors[0]].shape[0]\n",
    "\n",
    "train_LD = _batch_data_dict(train_dict, n_train_samples, batch_size)\n",
    "\n",
    "if n_samples - n_train_samples > MAX_BATCH_SIZE:\n",
    "    val_LD = _batch_data_dict(val_dict, n_samples - n_train_samples,\n",
    "                              MAX_BATCH_SIZE)\n",
    "else:\n",
    "    val_LD = [val_dict]\n",
    "\n",
    "train_LD = _set_train_mode_to_LD(train_LD, True)\n",
    "val_LD = _set_train_mode_to_LD(val_LD, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aca",
   "language": "python",
   "name": "aca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
