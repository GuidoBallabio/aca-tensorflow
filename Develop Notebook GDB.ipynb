{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Cifar-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first notebook we are going to explain how we have set up our work.  \n",
    "Essentially the process is divided into several parts:\n",
    "* Set up environment with the Cifar-10 Dataset\n",
    "* Define a convolutional neural network\n",
    "* Define a quantization method\n",
    "* Train the convolutional neural network\n",
    "* Provide information about CNN's performance and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we are used:\n",
    "* Python 3.6\n",
    "* Tensorflow 1.8.0\n",
    "* *GPUs parallel calculation manager* nVidia CUDA 9.0\n",
    "* *GPU-accelerated library* nVidia cuDNN 7.1\n",
    "* or CPU optimized tensorflow for intel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io, graph_util\n",
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "\n",
    "from cnn.dense import (NET_NAME, dataset_preprocessing_by_keras, eval_fn,\n",
    "                       forward_pass, loss_fn)\n",
    "from cnn.model_class import MODELS_DIR, TfClassifier\n",
    "from cnn.utils.dataset import load_cifar10\n",
    "from cnn.utils.save_models import load_frozen_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cifar-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cifar-10 Dataset is taken from the official website www.cs.toronto.edu.\n",
    "\n",
    "Dataset is stored in the data directory: cnn/data. From Cifar-10 dataset we are going to take x_train, t_train, x_test and t_test.\n",
    "The training dataset set is used for training the CNN, the testing dataset is used for evaluate the performance and the accuracy of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, t_train, x_test, t_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 10), (10000, 32, 32, 3), (10000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, t_train.shape, x_test.shape, t_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It also needs to be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.68747891, -0.65572952, -0.63985482, ..., -0.95734874,\n",
       "        -1.00497283, -0.92559935],\n",
       "       [-0.65572952, -0.63985482, -0.59223073, ..., -0.92559935,\n",
       "        -1.02084753, -0.86210057],\n",
       "       [-0.7192283 , -0.63985482, -0.65572952, ..., -0.68747891,\n",
       "        -0.735103  , -0.70335361],\n",
       "       ...,\n",
       "       [-0.36998499, -0.7509777 , -1.00497283, ..., -0.25886212,\n",
       "        -0.24298742, -0.14773924],\n",
       "       [-0.25886212, -0.65572952, -1.19546919, ...,  0.31262694,\n",
       "        -0.00486698, -0.49698256],\n",
       "       [-0.27473681, -0.35411029, -1.11609571, ...,  0.75711843,\n",
       "         0.64599556,  0.28087755]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = dataset_preprocessing_by_keras(x_train)\n",
    "x_train[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a custom made wrapper for tensorfllow NN training and use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CNN is called *dense_cnn*. Here we will explain how it is composed.\n",
    "\n",
    "The CNN is composed by several layers. In the first part there are 2 **convolutional** layers and 2 **pooling** layers (they are alternated), then there are a *flatten* layer followed by a **relu** layer, a *dropout* layer and finally a **softmax** layer.\n",
    "\n",
    "The network uses a stochastic gradient descent optimizer and a categorical crossentropy loss.  \n",
    "To judge the performance of our model we are used a MSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfClassifier(NET_NAME, forward_pass, loss_fn, eval_fn,\n",
    "                     tf.train.AdamOptimizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is trained for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training: tensorboard --logdir=/tmp/log-tb/dense_cnn/training\n",
      "For validation: tensorboard --logdir=/tmp/log-tb/dense_cnn/validation\n",
      "{'logits': (array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32),), 'classes': (array([0, 0, 0, ..., 0, 0, 0]),), 'probabilities': (array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32),), 'accuracy': ((0.102, 0.1002),), 'mse': ((nan, nan),), 'loss': (nan,), 'summaries': (b'\\n\\x0b\\n\\x04loss\\x15\\xff\\xff\\xff\\xff\\n\\x11\\n\\naccuracy_1\\x15`\\xe5\\xd0=\\n\\n\\n\\x03mse\\x15\\x00\\x00\\xc0\\xff',)}\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_train, t_train],\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    epochs=1,\n",
    "    verbosity=1,\n",
    "    keep_prob=0.5)\n",
    "\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it's evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/daibak/Documents/Code/Python/aca-tensorflow/cnn/models/dense_cnn/model.ckpt\n",
      "[{'logits': array([[  58.449165 ,  -40.94816  ,   -5.6226172, ...,  -94.2457   ,\n",
      "          43.86064  ,  -68.44922  ],\n",
      "       [  -9.421125 ,   -2.6976483,  -56.005733 , ...,  -15.75792  ,\n",
      "          16.243078 ,  -80.76974  ],\n",
      "       [  88.704    ,  -35.250233 ,  -27.641563 , ..., -143.42578  ,\n",
      "         217.6601   ,   21.607813 ],\n",
      "       ...,\n",
      "       [ -35.267845 ,   -7.7263284,  -25.900536 , ...,   25.24029  ,\n",
      "           5.2269926,  -20.619165 ],\n",
      "       [  45.99917  ,  119.776566 , -125.03786  , ...,  -61.233307 ,\n",
      "         179.8653   ,   47.13309  ],\n",
      "       [  22.152536 ,  -10.786198 ,  -36.33955  , ..., -121.99178  ,\n",
      "         116.80828  ,   32.390125 ]], dtype=float32), 'classes': array([0, 3, 8, ..., 5, 8, 8]), 'probabilities': array([[9.9999952e-01, 0.0000000e+00, 1.4927161e-28, ..., 0.0000000e+00,\n",
      "        4.6161975e-07, 0.0000000e+00],\n",
      "       [3.5268134e-31, 2.9332640e-28, 0.0000000e+00, ..., 6.2423108e-34,\n",
      "        4.9340416e-20, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [6.6077851e-30, 6.0420461e-18, 7.7308418e-26, ..., 1.2543077e-03,\n",
      "        2.5511689e-12, 1.5201829e-23],\n",
      "       [0.0000000e+00, 8.0130210e-27, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 2.1760185e-37]], dtype=float32), 'accuracy': (0.0, 0.3295), 'mse': (0.0, 14651.432), 'loss': 66.92384, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\x02\\xd9\\x85B\\n\\x11\\n\\naccuracy_1\\x15\\x00\\x00\\x00\\x00\\n\\n\\n\\x03mse\\x15\\x00\\x00\\x00\\x00'}, {'logits': array([[ -42.861507 ,   68.084076 , -123.29671  , ..., -115.98757  ,\n",
      "          26.015644 ,   76.17854  ],\n",
      "       [ 135.01825  ,  111.09117  ,  -37.476257 , ..., -124.922676 ,\n",
      "         193.4255   ,   20.449968 ],\n",
      "       [  18.012424 ,  -25.678225 ,  -22.017536 , ...,  -11.532805 ,\n",
      "          62.711304 ,   10.744349 ],\n",
      "       ...,\n",
      "       [  22.02229  ,   69.159966 ,  -99.58397  , ...,   -1.3615682,\n",
      "         -18.017876 ,  140.48529  ],\n",
      "       [  31.09459  ,   15.551247 ,  -54.834347 , ...,  -87.34103  ,\n",
      "         113.208954 ,   -1.5786377],\n",
      "       [  83.889984 ,   18.565737 ,   -1.9847757, ..., -113.281204 ,\n",
      "          80.26566  ,  -37.790752 ]], dtype=float32), 'classes': array([9, 8, 8, ..., 9, 8, 0]), 'probabilities': array([[0.0000000e+00, 3.0513012e-04, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.6383147e-22, 9.9969494e-01],\n",
      "       [4.3057680e-26, 1.7484474e-36, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       [3.8683295e-20, 0.0000000e+00, 1.5949025e-37, ..., 5.7041738e-33,\n",
      "        1.0000000e+00, 2.6979715e-23],\n",
      "       ...,\n",
      "       [0.0000000e+00, 1.0563432e-31, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 1.0000000e+00],\n",
      "       [2.1786359e-36, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       [9.7402543e-01, 4.1553669e-29, 4.9389482e-38, ..., 0.0000000e+00,\n",
      "        2.5974531e-02, 0.0000000e+00]], dtype=float32), 'accuracy': (0.3295, 0.32775), 'mse': (14651.432, 14725.559), 'loss': 69.39487, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15,\\xca\\x8aB\\n\\x11\\n\\naccuracy_1\\x159\\xb4\\xa8>\\n\\n\\n\\x03mse\\x15\\xba\\xeddF'}, {'logits': array([[ 231.96716 ,   41.62205 ,  -29.554337, ..., -136.7635  ,\n",
      "         194.68137 ,   -2.397997],\n",
      "       [ 152.8617  ,  133.96062 , -117.11271 , ..., -236.12067 ,\n",
      "         320.8651  ,   94.71111 ],\n",
      "       [ 239.72537 ,   87.501785,  -22.310883, ..., -170.25989 ,\n",
      "         298.6308  ,   65.33827 ],\n",
      "       ...,\n",
      "       [  53.363953,   67.24453 ,   70.27594 , ...,  -56.5647  ,\n",
      "          12.632701,  -76.66707 ],\n",
      "       [ -10.511704,   -5.022235,  -24.23229 , ...,  -71.7543  ,\n",
      "         -21.641811,  -26.274738],\n",
      "       [  29.00904 ,   30.201502,  -82.80867 , ..., -106.593346,\n",
      "         153.02087 ,    9.787605]], dtype=float32), 'classes': array([0, 8, 8, ..., 2, 3, 8]), 'probabilities': array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        6.4118607e-17, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       [2.6163666e-26, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.3127411e-08, 4.6026867e-02, 9.5397311e-01, ..., 0.0000000e+00,\n",
      "        8.8185257e-26, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00]], dtype=float32), 'accuracy': (0.32775, 0.32716668), 'mse': (14725.559, 14649.749), 'loss': 67.79993, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\x90\\x99\\x87B\\n\\x11\\n\\naccuracy_1\\x15\\xd9\\xce\\xa7>\\n\\n\\n\\x03mse\\x15<\\x16fF'}, {'logits': array([[  60.42943  ,  -14.134864 ,    4.395426 , ...,  -49.75998  ,\n",
      "           5.6746855,  -49.12391  ],\n",
      "       [ -42.18232  ,  -23.630577 , -100.97712  , ...,   34.888405 ,\n",
      "         -18.16686  ,   22.973595 ],\n",
      "       [ -39.51556  ,   -8.607806 ,  -27.834356 , ...,   -7.6525745,\n",
      "          -4.721447 ,   -7.6328983],\n",
      "       ...,\n",
      "       [ -23.800306 , -125.93824  ,   12.572109 , ...,   78.05098  ,\n",
      "        -142.07199  ,  -87.87119  ],\n",
      "       [  54.09524  ,  162.14516  ,  -75.20964  , ..., -182.15552  ,\n",
      "          28.41861  ,  142.17108  ],\n",
      "       [ -90.683075 ,   27.611706 ,  -56.636967 , ..., -145.17691  ,\n",
      "          52.038834 ,   21.5453   ]], dtype=float32), 'classes': array([0, 7, 5, ..., 5, 1, 6]), 'probabilities': array([[1.0000000e+00, 4.1413232e-33, 4.6210560e-25, ..., 0.0000000e+00,\n",
      "        1.6608021e-24, 0.0000000e+00],\n",
      "       [3.3653157e-34, 3.8365883e-26, 0.0000000e+00, ..., 9.9635953e-01,\n",
      "        9.0532872e-24, 6.6662224e-06],\n",
      "       [5.6759615e-24, 1.5035088e-10, 6.7161591e-19, ..., 3.9080258e-10,\n",
      "        7.3270767e-09, 3.9856821e-10],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 8.0146636e-29,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 2.1152871e-09],\n",
      "       [0.0000000e+00, 2.7453264e-21, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.1147072e-10, 6.3677685e-24]], dtype=float32), 'accuracy': (0.32716668, 0.327125), 'mse': (14649.749, 14773.408), 'loss': 68.90207, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\xdc\\xcd\\x89B\\n\\x11\\n\\naccuracy_1\\x15d\\x82\\xa7>\\n\\n\\n\\x03mse\\x15\\xff\\xe6dF'}, {'logits': array([[ -31.385494 ,  124.01619  ,  -87.60156  , ..., -149.22847  ,\n",
      "           6.195256 ,   68.69174  ],\n",
      "       [  47.066536 ,  -74.359924 ,  -40.27415  , ...,   -4.538248 ,\n",
      "          54.37802  ,    4.6817927],\n",
      "       [  10.328207 ,    5.696112 ,  -24.63046  , ...,  -84.30711  ,\n",
      "         131.34125  ,  -25.227037 ],\n",
      "       ...,\n",
      "       [  89.59186  ,  105.47219  ,  -87.589035 , ...,  -67.55313  ,\n",
      "         203.88765  ,    8.546838 ],\n",
      "       [  52.04953  ,  137.92863  , -114.91954  , ..., -133.98096  ,\n",
      "          97.50491  ,  155.7475   ],\n",
      "       [  61.838993 ,  138.00854  ,  -20.74827  , ...,   39.95933  ,\n",
      "           8.869154 ,   43.962883 ]], dtype=float32), 'classes': array([1, 8, 8, ..., 8, 9, 1]), 'probabilities': array([[0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 9.3950208e-25],\n",
      "       [6.6737871e-04, 0.0000000e+00, 0.0000000e+00, ..., 2.5864275e-26,\n",
      "        9.9933261e-01, 2.6116352e-22],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 1.8254342e-08, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        5.0765319e-26, 1.0000000e+00],\n",
      "       [8.3173003e-34, 1.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), 'accuracy': (0.327125, 0.3304), 'mse': (14773.408, 14990.489), 'loss': 67.71613, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\xa9n\\x87B\\n\\x11\\n\\naccuracy_1\\x15\\xee|\\xa7>\\n\\n\\n\\x03mse\\x15\\xa2\\xd5fF'}]\n"
     ]
    }
   ],
   "source": [
    "evals = model.evaluate([x_test, t_test])\n",
    "\n",
    "print(evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_graph()\n",
    "graph, inp, out = model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'features' type=Placeholder>,\n",
       " <tf.Operation 'conv2d/kernel' type=VariableV2>,\n",
       " <tf.Operation 'conv2d/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2d/bias' type=VariableV2>,\n",
       " <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2d/Relu' type=Relu>,\n",
       " <tf.Operation 'max_pooling2d/MaxPool' type=MaxPool>,\n",
       " <tf.Operation 'conv2d_1/kernel' type=VariableV2>,\n",
       " <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2d_1/bias' type=VariableV2>,\n",
       " <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2d_1/Relu' type=Relu>,\n",
       " <tf.Operation 'max_pooling2d_1/MaxPool' type=MaxPool>,\n",
       " <tf.Operation 'flatten/Shape' type=Shape>,\n",
       " <tf.Operation 'flatten/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'flatten/Reshape/shape/1' type=Const>,\n",
       " <tf.Operation 'flatten/Reshape/shape' type=Pack>,\n",
       " <tf.Operation 'flatten/Reshape' type=Reshape>,\n",
       " <tf.Operation 'dense/kernel' type=VariableV2>,\n",
       " <tf.Operation 'dense/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dense/bias' type=VariableV2>,\n",
       " <tf.Operation 'dense/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dense/Relu' type=Relu>,\n",
       " <tf.Operation 'logits/kernel' type=VariableV2>,\n",
       " <tf.Operation 'logits/MatMul' type=MatMul>,\n",
       " <tf.Operation 'logits/bias' type=VariableV2>,\n",
       " <tf.Operation 'logits/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'softmax' type=Softmax>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_graph = model.optimize_for_inference(add_transf=[\"sort_by_execution_order\"])\n",
    "opt_graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'features' type=Placeholder>,\n",
       " <tf.Operation 'conv2d/kernel' type=Const>,\n",
       " <tf.Operation 'conv2d/kernel/read' type=Identity>,\n",
       " <tf.Operation 'conv2d/bias' type=Const>,\n",
       " <tf.Operation 'conv2d/bias/read' type=Identity>,\n",
       " <tf.Operation 'conv2d/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2d/Relu' type=Relu>,\n",
       " <tf.Operation 'max_pooling2d/MaxPool' type=MaxPool>,\n",
       " <tf.Operation 'conv2d_1/kernel' type=Const>,\n",
       " <tf.Operation 'conv2d_1/kernel/read' type=Identity>,\n",
       " <tf.Operation 'conv2d_1/bias' type=Const>,\n",
       " <tf.Operation 'conv2d_1/bias/read' type=Identity>,\n",
       " <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2d_1/Relu' type=Relu>,\n",
       " <tf.Operation 'max_pooling2d_1/MaxPool' type=MaxPool>,\n",
       " <tf.Operation 'flatten/Shape' type=Shape>,\n",
       " <tf.Operation 'flatten/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'flatten/Reshape/shape/1' type=Const>,\n",
       " <tf.Operation 'flatten/Reshape/shape' type=Pack>,\n",
       " <tf.Operation 'flatten/Reshape' type=Reshape>,\n",
       " <tf.Operation 'dense/kernel' type=Const>,\n",
       " <tf.Operation 'dense/kernel/read' type=Identity>,\n",
       " <tf.Operation 'dense/bias' type=Const>,\n",
       " <tf.Operation 'dense/bias/read' type=Identity>,\n",
       " <tf.Operation 'dense/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dense/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dense/Relu' type=Relu>,\n",
       " <tf.Operation 'dropout/Identity' type=Identity>,\n",
       " <tf.Operation 'logits/kernel' type=Const>,\n",
       " <tf.Operation 'logits/kernel/read' type=Identity>,\n",
       " <tf.Operation 'logits/bias' type=Const>,\n",
       " <tf.Operation 'logits/bias/read' type=Identity>,\n",
       " <tf.Operation 'logits/MatMul' type=MatMul>,\n",
       " <tf.Operation 'logits/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'softmax' type=Softmax>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_operations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aca",
   "language": "python",
   "name": "aca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
