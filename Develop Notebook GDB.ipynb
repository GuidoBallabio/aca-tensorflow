{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Cifar-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first notebook we are going to explain how we have set up our work.  \n",
    "Essentially the process is divided into several parts:\n",
    "* Set up environment with the Cifar-10 Dataset\n",
    "* Define a convolutional neural network\n",
    "* Define a quantization method\n",
    "* Train the convolutional neural network\n",
    "* Provide information about CNN's performance and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we are used:\n",
    "* Python 3.6\n",
    "* Tensorflow 1.8.0\n",
    "* *GPUs parallel calculation manager* nVidia CUDA 9.0\n",
    "* *GPU-accelerated library* nVidia cuDNN 7.1\n",
    "* or CPU optimized tensorflow for intel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daibak/.virtualenvs/aca/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io, graph_util\n",
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "\n",
    "from cnn.dense import (NET_NAME, dataset_preprocessing_by_keras, eval_fn,\n",
    "                       forward_pass, loss_fn)\n",
    "from cnn.model_class import MODELS_DIR, TfClassifier\n",
    "from cnn.utils.dataset import load_cifar10\n",
    "from cnn.utils.save_models import load_frozen_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cifar-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cifar-10 Dataset is taken from the official website www.cs.toronto.edu.\n",
    "\n",
    "Dataset is stored in the data directory: cnn/data. From Cifar-10 dataset we are going to take x_train, t_train, x_test and t_test.\n",
    "The training dataset set is used for training the CNN, the testing dataset is used for evaluate the performance and the accuracy of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, t_train, x_test, t_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 10), (10000, 32, 32, 3), (10000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, t_train.shape, x_test.shape, t_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It also needs to be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.68747891, -0.65572952, -0.63985482, ..., -0.95734874,\n",
       "        -1.00497283, -0.92559935],\n",
       "       [-0.65572952, -0.63985482, -0.59223073, ..., -0.92559935,\n",
       "        -1.02084753, -0.86210057],\n",
       "       [-0.7192283 , -0.63985482, -0.65572952, ..., -0.68747891,\n",
       "        -0.735103  , -0.70335361],\n",
       "       ...,\n",
       "       [-0.36998499, -0.7509777 , -1.00497283, ..., -0.25886212,\n",
       "        -0.24298742, -0.14773924],\n",
       "       [-0.25886212, -0.65572952, -1.19546919, ...,  0.31262694,\n",
       "        -0.00486698, -0.49698256],\n",
       "       [-0.27473681, -0.35411029, -1.11609571, ...,  0.75711843,\n",
       "         0.64599556,  0.28087755]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = dataset_preprocessing_by_keras(x_train)\n",
    "x_train[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a custom made wrapper for tensorfllow NN training and use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CNN is called *dense_cnn*. Here we will explain how it is composed.\n",
    "\n",
    "The CNN is composed by several layers. In the first part there are 2 **convolutional** layers and 2 **pooling** layers (they are alternated), then there are a *flatten* layer followed by a **relu** layer, a *dropout* layer and finally a **softmax** layer.\n",
    "\n",
    "The network uses a stochastic gradient descent optimizer and a categorical crossentropy loss.  \n",
    "To judge the performance of our model we are used a MSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfClassifier(NET_NAME, forward_pass, loss_fn, eval_fn,\n",
    "                     tf.train.AdamOptimizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is trained for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training: tensorboard --logdir=/tmp/log-tb/dense_cnn/training\n",
      "For validation: tensorboard --logdir=/tmp/log-tb/dense_cnn/validation\n",
      "{'logits': (array([[-1.2727997 , -4.118344  ,  3.0404963 , ...,  0.434211  ,\n",
      "        -5.4986506 , -4.9266114 ],\n",
      "       [ 0.67287916,  5.107691  , -1.9640099 , ..., -2.370006  ,\n",
      "         0.5111373 ,  1.3213307 ],\n",
      "       [-0.58712345, -4.8890724 ,  2.3193388 , ...,  0.4489386 ,\n",
      "        -2.6303477 , -4.485857  ],\n",
      "       ...,\n",
      "       [-2.5256755 , -2.4960575 ,  0.04580361, ...,  1.2207695 ,\n",
      "        -2.8485522 , -1.5472312 ],\n",
      "       [ 0.07853588, -2.267046  , -1.6271029 , ...,  1.9091396 ,\n",
      "        -2.5177221 , -2.9749494 ],\n",
      "       [ 1.2112377 , -0.310529  , -0.02666046, ..., -2.1066892 ,\n",
      "         5.757359  , -1.0108342 ]], dtype=float32),), 'classes': (array([4, 1, 4, ..., 3, 4, 8]),), 'probabilities': (array([[3.6865592e-03, 2.1419890e-04, 2.7533537e-01, ..., 2.0322010e-02,\n",
      "        5.3871347e-05, 9.5453332e-05],\n",
      "       [1.1284639e-02, 9.5170397e-01, 8.0779538e-04, ..., 5.3824420e-04,\n",
      "        9.5994007e-03, 2.1582736e-02],\n",
      "       [1.1529479e-02, 1.5613384e-04, 2.1089688e-01, ..., 3.2491196e-02,\n",
      "        1.4943369e-03, 2.3367448e-04],\n",
      "       ...,\n",
      "       [1.8837147e-03, 1.9403406e-03, 2.4648717e-02, ..., 7.9813354e-02,\n",
      "        1.3639287e-03, 5.0112745e-03],\n",
      "       [2.1866512e-02, 2.0946250e-03, 3.9721904e-03, ..., 1.3639569e-01,\n",
      "        1.6301929e-03, 1.0319715e-03],\n",
      "       [1.0378539e-02, 2.2659032e-03, 3.0097056e-03, ..., 3.7599244e-04,\n",
      "        9.7834432e-01, 1.1248711e-03]], dtype=float32),), 'accuracy': ((0.6216, 0.6242),), 'mse': ((6.7074714, 6.8526835),), 'loss': (1.076631,), 'summaries': (b'\\n\\x0b\\n\\x04loss\\x15\\x0b\\xcf\\x89?\\n\\x11\\n\\naccuracy_1\\x15-!\\x1f?\\n\\n\\n\\x03mse\\x15\\x9b\\xa3\\xd6@',)}\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_train, t_train],\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    epochs=1,\n",
    "    verbosity=1)\n",
    "\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it's evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/daibak/Documents/Code/Python/aca-tensorflow/cnn/models/dense_cnn/model.ckpt\n",
      "[{'logits': array([[  81.05848 ,  -62.064182,  -43.652035, ...,  -53.434326,\n",
      "        -106.73805 , -121.6701  ],\n",
      "       [ -63.58989 ,  -46.279205,  -69.02652 , ...,   46.97762 ,\n",
      "        -134.47418 , -105.88981 ],\n",
      "       [  91.31454 ,  -15.858677,  -87.60347 , ...,  -76.14768 ,\n",
      "         147.22803 ,   51.774258],\n",
      "       ...,\n",
      "       [ -22.75338 ,   -7.063589,  -56.86931 , ...,  107.1757  ,\n",
      "         -97.29552 ,  -37.601997],\n",
      "       [  33.548573,  113.97623 , -139.0345  , ...,   60.917297,\n",
      "         -21.515625,  165.21643 ],\n",
      "       [  11.03273 ,  -16.96773 ,  -55.12688 , ...,  -70.942825,\n",
      "          18.96115 ,   64.09692 ]], dtype=float32), 'classes': array([0, 3, 8, ..., 7, 9, 3]), 'probabilities': array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 6.6681065e-21,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.2129043e-25, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 5.5803610e-23, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 1.0000000e+00],\n",
      "       [2.5590831e-24, 1.7686430e-36, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        7.1015629e-21, 2.8416303e-01]], dtype=float32), 'accuracy': (0.0, 0.451), 'mse': (0.0, 14241.188), 'loss': 43.29975, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\xf22-B\\n\\x11\\n\\naccuracy_1\\x15\\x00\\x00\\x00\\x00\\n\\n\\n\\x03mse\\x15\\x00\\x00\\x00\\x00'}, {'logits': array([[  20.460281 ,    5.3891306, -111.37515  , ...,   34.62735  ,\n",
      "         -33.981796 ,   24.281185 ],\n",
      "       [ 134.09827  ,   62.564865 , -142.80728  , ...,  -87.46766  ,\n",
      "         223.30058  ,   91.93571  ],\n",
      "       [  -4.0094895,  -29.042316 ,  -48.310894 , ...,   27.39673  ,\n",
      "           4.4798546,   13.545049 ],\n",
      "       ...,\n",
      "       [  23.878979 ,    0.9489373,  -98.30216  , ...,   84.28419  ,\n",
      "         -43.395103 ,   80.39508  ],\n",
      "       [  51.141926 ,  -32.984306 ,  -60.38281  , ...,  -10.920335 ,\n",
      "          64.43309  ,  -40.634876 ],\n",
      "       [  55.58632  ,  -40.103786 ,    2.8208137, ...,  -84.349205 ,\n",
      "        -104.537125 , -100.8458   ]], dtype=float32), 'classes': array([7, 8, 7, ..., 7, 8, 3]), 'probabilities': array([[7.0356805e-07, 2.0044170e-13, 0.0000000e+00, ..., 9.9996722e-01,\n",
      "        1.5973949e-30, 3.2114676e-05],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00],\n",
      "       [2.2932521e-14, 3.0819970e-25, 1.3200650e-33, ..., 9.9999905e-01,\n",
      "        1.1151336e-10, 9.6447434e-07],\n",
      "       ...,\n",
      "       [5.7220781e-27, 6.2974250e-37, 0.0000000e+00, ..., 9.7994679e-01,\n",
      "        0.0000000e+00, 2.0053256e-02],\n",
      "       [1.6893512e-06, 0.0000000e+00, 0.0000000e+00, ..., 1.8811486e-33,\n",
      "        9.9999833e-01, 0.0000000e+00],\n",
      "       [2.2444489e-08, 0.0000000e+00, 2.7248528e-31, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), 'accuracy': (0.451, 0.45475), 'mse': (14241.188, 14363.684), 'loss': 44.197662, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15h\\xca0B\\n\\x11\\n\\naccuracy_1\\x15y\\xe9\\xe6>\\n\\n\\n\\x03mse\\x15\\xc1\\x84^F'}, {'logits': array([[ 160.5733   ,  101.178604 , -105.42473  , ...,   -9.1747675,\n",
      "          77.77568  ,  110.81963  ],\n",
      "       [ 356.604    ,  172.23866  ,  -91.99483  , ..., -109.134865 ,\n",
      "         226.44115  ,  108.005585 ],\n",
      "       [ 306.71353  ,  128.0972   , -123.78629  , ..., -103.89398  ,\n",
      "         229.51685  ,   67.542694 ],\n",
      "       ...,\n",
      "       [   6.3418455,    1.1219839,  -17.232256 , ...,   62.000774 ,\n",
      "        -109.26398  ,  -38.08551  ],\n",
      "       [  -5.986167 ,  -98.78028  ,  -43.250507 , ...,  -43.487545 ,\n",
      "        -129.12723  ,  -78.05958  ],\n",
      "       [  71.782776 ,   23.617708 ,  -74.390465 , ...,  -39.29129  ,\n",
      "         118.89633  ,  -20.417324 ]], dtype=float32), 'classes': array([0, 0, 0, ..., 4, 3, 8]), 'probabilities': array([[1.0000000e+00, 1.6040208e-26, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.1001438e-36, 2.4674925e-22],\n",
      "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        2.9778679e-34, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.4264440e-34, 7.7143610e-37, 0.0000000e+00, ..., 2.1213951e-10,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.4581412e-21, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        1.0000000e+00, 0.0000000e+00]], dtype=float32), 'accuracy': (0.45475, 0.45133334), 'mse': (14363.684, 14206.44), 'loss': 46.17686, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\x1b\\xb58B\\n\\x11\\n\\naccuracy_1\\x15\\xfe\\xd4\\xe8>\\n\\n\\n\\x03mse\\x15\\xbcn`F'}, {'logits': array([[  31.591412 ,  -97.26259  ,  -86.84316  , ...,  -15.522716 ,\n",
      "        -185.43584  ,  -82.67186  ],\n",
      "       [ -82.67961  ,  -58.465855 , -149.29463  , ...,  132.47873  ,\n",
      "        -123.35545  ,   34.576756 ],\n",
      "       [ -37.28244  ,  -47.902946 ,   -7.8740015, ...,  137.82047  ,\n",
      "         -79.242226 ,  -48.466564 ],\n",
      "       ...,\n",
      "       [ -32.48986  , -284.56122  ,    0.9092644, ...,  155.1799   ,\n",
      "        -189.94482  , -177.96777  ],\n",
      "       [  -6.450541 ,  123.479836 ,  -68.7411   , ..., -107.621315 ,\n",
      "         -12.630596 ,  109.40741  ],\n",
      "       [ -87.79523  ,    6.0766063,  -25.477318 , ..., -114.79908  ,\n",
      "           9.758338 ,   18.97808  ]], dtype=float32), 'classes': array([3, 7, 7, ..., 5, 1, 6]), 'probabilities': array([[5.3884032e-32, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 8.8554535e-24,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 9.9999928e-01, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 7.7343321e-07],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), 'accuracy': (0.45133334, 0.45), 'mse': (14206.44, 14290.893), 'loss': 43.53008, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\xcd\\x1e.B\\n\\x11\\n\\naccuracy_1\\x15*\\x15\\xe7>\\n\\n\\n\\x03mse\\x15\\xc3\\xf9]F'}, {'logits': array([[ -38.918877,   39.277313,  -69.17116 , ...,  -65.13004 ,\n",
      "         -35.84767 ,   25.011229],\n",
      "       [  64.33715 ,  -80.58186 ,  -45.275112, ...,   82.24015 ,\n",
      "         -24.820421,   21.074896],\n",
      "       [  22.835653,   12.179938,  -22.563179, ...,  -11.610273,\n",
      "          39.864216,  -13.440799],\n",
      "       ...,\n",
      "       [  97.76762 ,  131.34843 , -113.70898 , ...,  -44.465435,\n",
      "         107.28789 ,  140.65697 ],\n",
      "       [  27.749224,   39.017143, -163.1041  , ..., -112.092606,\n",
      "          65.44777 ,  119.4071  ],\n",
      "       [ -16.814943,  -59.81433 ,  -59.075855, ...,  374.20032 ,\n",
      "        -171.93938 ,  -98.60566 ]], dtype=float32), 'classes': array([3, 7, 8, ..., 9, 9, 7]), 'probabilities': array([[0.0000000e+00, 1.9303413e-13, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 1.2301360e-19],\n",
      "       [1.6781314e-08, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
      "        0.0000000e+00, 2.7306646e-27],\n",
      "       [4.0233637e-08, 9.4813784e-13, 7.7290650e-28, ..., 4.4148329e-23,\n",
      "        1.0000000e+00, 7.0782509e-24],\n",
      "       ...,\n",
      "       [2.3623937e-19, 9.0639245e-05, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        3.2207244e-15, 9.9990940e-01],\n",
      "       [0.0000000e+00, 1.2220440e-35, 0.0000000e+00, ..., 0.0000000e+00,\n",
      "        3.6792713e-24, 1.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), 'accuracy': (0.45, 0.4507), 'mse': (14290.893, 14498.875), 'loss': 45.235367, 'summaries': b'\\n\\x0b\\n\\x04loss\\x15\\x04\\xf14B\\n\\x11\\n\\naccuracy_1\\x15ff\\xe6>\\n\\n\\n\\x03mse\\x15\\x92K_F'}]\n"
     ]
    }
   ],
   "source": [
    "evals = model.evaluate([x_test, t_test])\n",
    "\n",
    "print(evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, inp, out = load_frozen_graph(\n",
    "    (MODELS_DIR / model.name / 'model.pb').as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, out = (['features'], ['softmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['features'], ['softmax'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=model.predict_ops_graph[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'logits/bias' type=VariableV2>,\n",
       " <tf.Operation 'logits/kernel' type=VariableV2>,\n",
       " <tf.Operation 'dense/bias' type=VariableV2>,\n",
       " <tf.Operation 'dense/kernel' type=VariableV2>,\n",
       " <tf.Operation 'flatten/Reshape/shape/1' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'conv2d_1/bias' type=VariableV2>,\n",
       " <tf.Operation 'conv2d_1/kernel' type=VariableV2>,\n",
       " <tf.Operation 'conv2d/bias' type=VariableV2>,\n",
       " <tf.Operation 'conv2d/kernel' type=VariableV2>,\n",
       " <tf.Operation 'conv2d/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2d/Relu' type=Relu>,\n",
       " <tf.Operation 'max_pooling2d/MaxPool' type=MaxPool>,\n",
       " <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2d_1/Relu' type=Relu>,\n",
       " <tf.Operation 'max_pooling2d_1/MaxPool' type=MaxPool>,\n",
       " <tf.Operation 'flatten/Shape' type=Shape>,\n",
       " <tf.Operation 'flatten/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'flatten/Reshape/shape' type=Pack>,\n",
       " <tf.Operation 'flatten/Reshape' type=Reshape>,\n",
       " <tf.Operation 'dense/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dense/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dense/Relu' type=Relu>,\n",
       " <tf.Operation 'logits/MatMul' type=MatMul>,\n",
       " <tf.Operation 'logits/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'softmax' type=Softmax>,\n",
       " <tf.Operation 'features' type=Placeholder>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_graph = model.optimize_for_inference(add_transf=[])\n",
    "opt_graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'train_mode' type=Placeholder>,\n",
       " <tf.Operation 'features' type=Placeholder>,\n",
       " <tf.Operation 'conv2d/kernel' type=Const>,\n",
       " <tf.Operation 'conv2d/kernel/read' type=Identity>,\n",
       " <tf.Operation 'conv2d/bias' type=Const>,\n",
       " <tf.Operation 'conv2d/bias/read' type=Identity>,\n",
       " <tf.Operation 'conv2d/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2d/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2d/Relu' type=Relu>,\n",
       " <tf.Operation 'max_pooling2d/MaxPool' type=MaxPool>,\n",
       " <tf.Operation 'conv2d_1/kernel' type=Const>,\n",
       " <tf.Operation 'conv2d_1/kernel/read' type=Identity>,\n",
       " <tf.Operation 'conv2d_1/bias' type=Const>,\n",
       " <tf.Operation 'conv2d_1/bias/read' type=Identity>,\n",
       " <tf.Operation 'conv2d_1/Conv2D' type=Conv2D>,\n",
       " <tf.Operation 'conv2d_1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv2d_1/Relu' type=Relu>,\n",
       " <tf.Operation 'max_pooling2d_1/MaxPool' type=MaxPool>,\n",
       " <tf.Operation 'flatten/Shape' type=Shape>,\n",
       " <tf.Operation 'flatten/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'flatten/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'flatten/Reshape/shape/1' type=Const>,\n",
       " <tf.Operation 'flatten/Reshape/shape' type=Pack>,\n",
       " <tf.Operation 'flatten/Reshape' type=Reshape>,\n",
       " <tf.Operation 'dense/kernel' type=Const>,\n",
       " <tf.Operation 'dense/kernel/read' type=Identity>,\n",
       " <tf.Operation 'dense/bias' type=Const>,\n",
       " <tf.Operation 'dense/bias/read' type=Identity>,\n",
       " <tf.Operation 'dense/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dense/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dense/Relu' type=Relu>,\n",
       " <tf.Operation 'dropout/cond/Switch' type=Switch>,\n",
       " <tf.Operation 'dropout/cond/switch_t' type=Identity>,\n",
       " <tf.Operation 'dropout/cond/pred_id' type=Identity>,\n",
       " <tf.Operation 'dropout/cond/dropout/keep_prob' type=Const>,\n",
       " <tf.Operation 'dropout/cond/dropout/Shape' type=Shape>,\n",
       " <tf.Operation 'dropout/cond/dropout/Shape/Switch' type=Switch>,\n",
       " <tf.Operation 'dropout/cond/dropout/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'dropout/cond/dropout/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'dropout/cond/dropout/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'dropout/cond/dropout/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'dropout/cond/dropout/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'dropout/cond/dropout/random_uniform' type=Add>,\n",
       " <tf.Operation 'dropout/cond/dropout/add' type=Add>,\n",
       " <tf.Operation 'dropout/cond/dropout/Floor' type=Floor>,\n",
       " <tf.Operation 'dropout/cond/dropout/div' type=RealDiv>,\n",
       " <tf.Operation 'dropout/cond/dropout/mul' type=Mul>,\n",
       " <tf.Operation 'dropout/cond/Identity' type=Identity>,\n",
       " <tf.Operation 'dropout/cond/Identity/Switch' type=Switch>,\n",
       " <tf.Operation 'dropout/cond/Merge' type=Merge>,\n",
       " <tf.Operation 'logits/kernel' type=Const>,\n",
       " <tf.Operation 'logits/kernel/read' type=Identity>,\n",
       " <tf.Operation 'logits/bias' type=Const>,\n",
       " <tf.Operation 'logits/bias/read' type=Identity>,\n",
       " <tf.Operation 'logits/MatMul' type=MatMul>,\n",
       " <tf.Operation 'logits/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'softmax' type=Softmax>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fed_4:0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    h = tf.placeholder(tf.bool, shape=(), name='hungry')\n",
    "    f = tf.placeholder(tf.bool, shape=(), name='fed')\n",
    "    n = tf.logical_not(f)\n",
    "    o = sess.run(n, feed_dict={f: False})\n",
    "o\n",
    "f.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aca",
   "language": "python",
   "name": "aca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
